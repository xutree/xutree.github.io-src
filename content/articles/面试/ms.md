Title: 机器学习面试题目
Category: 其他
Tags: 机器学习

[TOC]

## 1. 理论

### 1.1 什么是偏差（bias）、方差（variable）之间的均衡（trade-off）？

偏差是学习算法中错误假设的误差。高偏差会导致算法错过特征与目标输出之间的相关关系（欠拟合）。

方差是训练集中数据小波动敏感程度。 高方差可导致算法对训练数据中的随机噪声进行建模，而不是预期的输出（过度拟合）。

偏差方差分解是一种分析学习算法的特定问题的预期泛化误差的方法，作为三个项的总和：偏差，方差和称为不可约误差（由问题本身的噪声引起）。

高方差学习方法可以很好地表示他们的训练集，但是存在过度拟合到嘈杂或不具代表性的训练数据的风险。相比之下，具有低方差的算法通常会生成更简单的模型，这些模型不会过度拟合，但可能会使其训练数据不适应，无法捕获重要的规律。

低偏差的模型通常更复杂（例如，高阶回归多项式），使得它们能够更准确地表示训练集。然而，在这个过程中，它们也可能代表训练集中的大噪声成分，使得它们的预测不太准确 - 尽管它们增加了复杂性。相反，具有较高偏差的模型倾向于相对简单（低阶或甚至线性回归多项式），但是当应用于训练集之外时可能产生较低的方差预测。

在回归问题中，虽然最小二乘法提供了无偏的回归估计，但是引入正则化项的低方差版本比 MSE 性能更好。

减少维度和特征可以减小方差（因为模型变得简单）；增大训练集也可以减少方差。

增加特征可以减小偏差。

线性模型和广义线性模型可以被正则化以减少它们的方差，但代价是增加它们的偏差。

在人工神经网络中，随着隐藏单元数量的增加，方差增加，偏差减小。 与广义线性模型类似，通常应用正则化。

在 $k$ 最近邻模型中，高 $k$ 值导致高偏差和低方差。

在决策树中，树的深度决定了方差，决策树通常被修剪以控制方差。

解决这种权衡的一种方法是使用混合模型和集成学习。例如，提升方法增强结合了许多“弱”（高偏差）模型，其集合中的偏差低于单个模型，而装袋算法结合了许多“强”模型以减少其方差。

### 1.2 监督学习和非监督学习有什么不同？

分类和回归是监督学习的代表，而聚类是非监督学习的代表。

监督学习其实就是我们对输入样本经过模型训练后有明确的预期输出，非监督学习就是我们对输入样本经过模型训练后得到什么输出完全没有预期。

监督学习需要 train 有 label 的数据，以便将数据分类到标记的组中。相反的，无监督学习不需要明确标记数据。

### 1.3 $k$ NN 和 k-means 聚类有什么不同？

$k$-NN 需要标记点，是有监督的学习，而 k-means 不是，是无监督学习。

$k$ 均值聚类仅需要一组未标记的点和阈值：算法将采用未标记的点并逐渐学习如何通过计算不同点之间的距离的平均值将它们聚类成组。

### 1.4 解释一下 ROC 曲线的原理。

在信号检测理论中，接收者操作特征曲线（receiver operating characteristic curve，或者叫 ROC 曲线）是一种坐标图式的分析工具，用于：

- 选择最佳的信号侦测模型、舍弃次佳的模型
- 在同一模型中设定最佳阈值

ROC 分析的是二元分类模型，二元分类模型的个案预测有四种结局：

- 真阳性（TP）：诊断为有，实际上也有高血压
- 伪阳性（FP）：诊断为有，实际却没有高血压
- 真阴性（TN）：诊断为没有，实际上也没有高血压
- 伪阴性（FN）：诊断为没有，实际却有高血压

ROC 空间将伪阳性率（FPR）定义为 $x$ 轴，真阳性率（TPR）定义为 $y$ 轴。

- FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率 FPR=$\frac{\text{FP}}{\text{FP+TN}}$
- TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率
TPR=$\frac{\text{TP}}{\text{TP+FN}}$

给定一个二元分类模型和它的阈值，就能从所有样本的（阳性／阴性）真实值和预测值计算出一个 ($x$=FPR, $y$=TPR) 座标点。

从 (0, 0) 到 (1,1) 的对角线将 ROC 空间划分为左上／右下两个区域，在这条线的以上的点代表了一个好的分类结果（胜过随机分类），而在这条线以下的点代表了差的分类结果（劣于随机分类）。

完美的预测是一个在左上角的点，在 ROC 空间座标 (0,1)点，$x$=0 代表着没有伪阳性，$y$=1 代表着没有伪阴性（所有的阳性都是真阳性）；也就是说，不管分类器输出结果是阳性或阴性，都是 100% 正确。一个随机的预测会得到位于从 (0, 0) 到 (1, 1) 对角线（也叫无识别率线）上的一个点；最直观的随机预测的例子就是抛硬币。

上述 ROC 空间里的单点，是给定分类模型且给定阈值后得出的。但同一个二元分类模型的阈值可能设定为高或低，每种阈值的设定会得出不同的 FPR 和 TPR。

将同一模型每个阈值 的 (FPR, TPR) 座标都画在 ROC 空间里，就成为特定模型的 ROC 曲线。

在同一个分类器之内：

- 当阈值设定为最高时，没有样本被预测为阳性，必得出 ROC 座标系左下角的点 (0, 0)
- 当阈值设定为最低时，没有样本被预测为阴性，必得出 ROC 座标系右上角的点 (1, 1)
- 因为 TP、FP、TN、FN 都是累积次数，TN 和 FN 随着阈值调低而减少（或持平），TP 和 FP 随着阈值调低而增加（或持平），所以 FPR 和 TPR 皆必随着阈值调低而增加（或持平），随着阈值调低，ROC点 往右上（或右／或上）移动，或不动；但绝不会往左下(或左／或下)移动

曲线下面积（AUC）：

ROC 曲线下方的面积（Area under the Curve of ROC (AUC ROC)），其意义是：

- 因为是在 1x1 的方格里求面积，AUC 必在 0~1 之间
- 假设阈值以上是阳性，以下是阴性
- 若随机抽取一个阳性样本和一个阴性样本，分类器正确判断阳性样本的值高于阴性样本之几率为 AUC。
- 简单说：AUC 值越大的分类器，正确率越高

从 AUC 判断分类器（预测模型）优劣的标准：

- AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器
- 0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值
- AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值
- AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测

### 1.5 精确率（precision），召回率（recall）与特异性（specificity）

P=$\frac{\text{TP}}{\text{TP+FP}}$

R=$\frac{\text{TP}}{\text{TP+FN}}$

S=$\frac{\text{TN}}{\text{FP+TN}}$

$\frac{2}{\text{F}_1}=\frac{1}{\text{P}}+\frac{1}{\text{R}}$

以精确率为 $y$ 轴，以召回率为 $x$ 轴，我们就得到了 PR 曲线。仍然从精确率和召回率的定义可以理解，精确率越高，召回率越高，我们的模型和算法就越高效。也就是画出来的 PR 曲线越靠近右上越好。

### 1.6 什么是贝叶斯定理？它在机器学习环境中如何有用?

贝叶斯定理是概率论中的一个定理，描述在已知一些条件下，某事件的发生概率。比如，如果已知某癌症与寿命有关，使用贝叶斯定理则可以通过得知某人年龄，来更加准确地计算出他罹患癌症的概率。

### 1.7 L1、L2 正则之间有什么不同？
