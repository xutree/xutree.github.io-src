Title: 统计学习方法 第十章 隐马尔科夫模型
Category: 读书笔记
Date: 2018-11-19 12:38:27
Modified: 2018-11-19 12:38:27
Tags: 统计学习, 机器学习

隐马尔科夫模型（hidden Markov model，HMM）是可用于标注问题的统计学模型，描述由隐藏的马尔科夫链随机生成观测序列的过程，属于生成模型。隐马尔科夫模型在语音识别、自然语言处理、生物信息、模式识别等领域有着广泛的应用。

## 10.1 隐马尔科夫模型的基本概念

### 10.1.1 隐马尔科夫模型的定义

**
定义 10.1（隐马尔科夫模型的定义）隐马尔科夫模型是关于时序的概率模型，描述由一个隐藏的马尔科夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔科夫链随机生成的状态的序列称为状态序列（state sequence）；每个状态生成一个观测，由此产生的观测随机序列称为观测序列（observation sequence）。序列的每一个位置又可以看作是一个时刻
**

隐马尔科夫模型由初始概率分布、状态转移概率分布以及观测概率分布确定。隐马尔科夫模型的形式定义如下：

设 $Q$ 是所有可能的状态的集合，$V$ 是所有可能的观测的集合
$$Q=\{q_1,q_2,\cdots,q_N\},\ V=\{v_1,v_2,\cdots,v_M\}$$
其中，$N$ 是可能的状态数，$M$ 是可能的观测数。

$I$ 是长度为 $T$ 的状态序列，$O$ 是对应的观测序列
$$I=\{i_1,i_2,\cdots,i_T\},\ O=\{o_1,o_2,\cdots,o_T\}$$

$A$ 是状态转移概率矩阵
$$A=\left[a_{ij}\right]_{N\times N}$$
其中
$$a_{ij}=P(i_{t+1}=q_j|i_t=q_i),\ i=1,2,\cdots,N;\ j=1,2,\cdots,N$$
是在 $t$ 时刻处于状态 $q_i$ 的条件下 $t+1$ 时刻转移到状态 $q_j$ 的概率。

$B$ 是观测概率矩阵
$$B=\left[b_j(k)\right]_{N\times M}$$
其中
$$b_j(k)=P(o_t=v_k|i_t=q_j),\ k=1,2,\cdots,M;\ j=1,2,\cdots,N$$
是在 $t$ 时刻处于状态 $q_j$ 的条件下观测生成 $v_k$ 的概率。

$\pi$ 是初始状态概率向量
$$\pi=(\pi_i)$$
其中
$$\pi_i=P(i_1=q_i),\ i=1,2,\cdots,N$$
是时刻 $t=1$ 处于状态 $q_i$ 的概率。

隐马尔科夫模型由初始状态概率向量 $\pi$，状态转移概率矩阵 $A$ 和观测概率矩阵 $B$ 决定。$\pi$ 和 $A$ 决定状态序列，$B$ 决定观测序列。隐马尔科夫模型 $\lambda$ 可以用三元符号表示，即
$$\lambda=(A,B,\pi)$$
称为隐马尔科夫模型的三要素。

隐马尔科夫模型作了两个基本假设：

a. 齐次马尔科夫性假设
$$P(i_t|i_{t-1},o_{t-1},\cdots,i_1,o_1)=P(i_t|i_{t-1}),\ t=1,2,\cdots,T$$
b. 观测独立性假设
$$P(o_t|i_T,o_T,i_{T-1},o_{T-1},\cdots,i_{t+1},o_{t+1},i_t,i_{t-1},o_{t-1},\cdots,i_1,o_1)=P(o_t|i_t)$$

隐马尔科夫模型可以用于标注问题，这时状态对应着标记。标注问题是给定观测的序列预测其对应的标记序列。可以假设标注问题的数据是由隐马尔科夫模型生成的。这样我们可以利用隐马尔科夫模型的学习与预测算法进行标注。

### 10.1.2 观测序列的生成过程

**
算法 10.1（观测序列的生成)  
输入：隐马尔科夫模型 $\lambda=(A,B,\pi)$，观测序列长度 $T$  
输出：观测序列 $O=(o_1,o_2,\cdots,o_T)$  
(1) 按照初始状态分布 $\pi$ 产生状态 $i_1$  
(2) 令 $t=1$  
(3) 按照状态 $i_t$ 的观测概率分布 $b_{i_t}(k)$ 生成 $o_t$  
(4) 按照状态 $i_t$ 的状态转移概率分布 $\{a_{i_ti_{t+1}}\}$ 产生状态 $i_{t+1}$，$i_{t+1}=1,2,\cdots,,N$  
(5) 令 $t=t+1$；如果 $t<T$，转 (3)；否则，终止
**

### 10.1.3 隐马尔科夫模型的 3 个基本问题

$\blacksquare$ 概率计算问题

给定模型 $\lambda=(A,B,\pi)$ 和观测序列 $O=(o_1,o_2,\cdots,o_T)$，计算在模型 $\lambda$ 下观测序列 $O$ 出现的概率 $P(O|\lambda)$ 。

$\blacksquare$ 学习问题

已知观测序列 $O=(o_1,o_2,\cdots,o_T)$，估计模型参数 $\lambda=(A,B,\pi)$，使得在该模型下观测序列 $P(O|\lambda)$ 最大。即用极大似然估计的方法估计参数。

$\blacksquare$ 预测问题

也称为解码（decoding）问题。已知模型 $\lambda=(A,B,\pi)$ 和观测序列 $O=(o_1,o_2,\cdots,o_T)$，求对给定观测序列条件概率 $P(I|O)$ 最大的状态序列 $I=(i_1,i_2,\cdots,i_T)$。即给定观测序列，求最可能的对应的状态序列。
