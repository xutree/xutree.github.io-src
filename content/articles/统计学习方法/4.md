Title: 统计学习方法 第四章 朴素贝叶斯法
Category: 读书笔记
Tags: 统计学习, 机器学习

朴素贝叶斯（naive Bayes）法是基于贝叶斯定理与特征条件独立假设的分类方法。朴素贝叶斯法实现简单，学习和预测效率都很高，是一种常用的方法。

## 4.1 朴素贝叶斯法的学习与分类

### 4.1.1 基本方法

设输入特征向量
$$x\in{\cal X}\subseteq\mathbb{R}^n$$
输出类标记
$$y\in{\cal Y}=\{c_1,c_2,\cdots,c_K\}$$
$X$ 是定义在输入空间 ${\cal X}$ 上的随机变量，$Y$ 是定义在输出空间 ${\cal Y}$ 上的随机变量，$P(X,Y)$ 是 $X$ 和 $Y$ 的联合概率分布。训练数据集
$$T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\}$$
由 $P(X,Y)$ 独立同分布产生。

朴素贝叶斯法通过训练数据集学习联合概率分布 $P(X,Y)$。具体地，学习以下先验概率分布及条件概率分布。先验概率分布
$$P(Y=c_k),k=1,2,\cdots,K$$
条件概率分布
$$P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},\cdots,X^{(n)}=x^{(n)}|Y=c_k),k=1,2,\cdots,K$$
于是学习到联合概率分布
$$P(X,Y)=P(X=x|Y=c_k)P(Y=c_k)$$

条件概率分布 $P(X=x|Y=c_k)$ 由指数级数量的参数，其估计实际是不可行的。事实上，假设 $x^{(i)}$ 可取值有 $S_j$ 个，$Y$ 可取值有 $K$ 个，那么参数个数为 $K\prod_{j=1}^nS_j$。
