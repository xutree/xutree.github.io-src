Title: 统计学习方法 第三章 k 近邻法
Category: 读书笔记
Date: 2018-11-04 23:11:36
Modified: 2018-11-04 23:30:30
Tags: 统计学习, 机器学习

$k$ 近邻法（k-nearest neighbor，$k$-NN）是一种基本分类与回归方法。$k$ 近邻法的输入为实例的特征向量，输出为实例的类别，可以取多类。$k$ 近邻法假设给定一个训练集数据，其中的实例类别已定。分类时，对新的实例，根据其 $k$ 个最近邻的训练实例的类别，通过多数表决等方式进行预测。因此，$k$ 近邻法不具有显式的学习过程。

$k$ 近邻法实际上利用训练数据集对特征向量空间进行划分，并作为其分类的模型。

$k$ 值得选择、距离度量以及分类决策规则是 $k$ 近邻法的三个基本要素。

## 3.1 $k$ 近邻算法

**算法 3.1 （$k$ 近邻法）  
输入：训练数据集
$$T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\}$$
其中
$$x_i\in{\cal X}\subseteq\mathbb{R}^n$$
为实例的特征空间，
$$y_i\in{\cal Y}=\{c_1,c_2,\cdots,c_K\}$$
为实例的类别；
实例特征向量 $x$  
输出：实例 $x$ 所属的类 $y$  
(1) 根据给定的距离度量，在训练集 $T$ 中找出与 $x$ 最邻近的 $k$ 个点，涵盖这 $k$ 个点的 $x$ 的邻域记作 $N_k(x)$  
(2) 在 $N_k(x)$  中根据分类决策规则（如多数表决）决定 $x$ 的类别 $y$
$$y=\arg\max_{c_j}\sum_{x_i\in N_k(x)}\mathbb{I}(y_i=c_j),i=1,2,\cdots,N; j=1,2,\cdots,K$$
式中，$\mathbb{I}$ 为指示函数
**

$k$ 近邻法的特殊情况是 $k=1$ 的情形，称为最近邻算法。对于输入的实例点（特征向量）$x$，最邻近法将数据集中与 $x$ 最邻近点的类作为 $x$ 的类。
